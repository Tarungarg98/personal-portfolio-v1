<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<link rel="stylesheet" href="style.css">
<title> Lokly - Address Parser </title>
</head>
<body>
<a href="index.html"><u>Back</u></a>
<br>
<h1 align='center'>Lokly - Indian Adress Parser</h3>
<br>
<div class="col-md-12";>
<div class="row">
<div class="col-md-6" align='justify' style="paddign-left:10px; padding-right:10px">
<br>
<h3 align='center'>What is it about ?</h3>
<br>
Addresses often provide a significant amount of intelligence about the buying and spending habits of a consumer. In most cases this intelligence cannot be determined from the address as most of the addresses are free flowing text and are not easily parsed. Faced with these challenges we have created an address parser exclusively for Indian addresses. Lokly the Indian address parser helps you parse an address contained in a free flowing string. Divide a single address (as string) into separate component parts : house number, street type (bd, street, ..), street name, unit (apt, batiment, ...), zipcode, state, country, city etc. Soon we would be adding intelligence around the neighborhoods to help you determine the economic value of the addresses.
<hr>
<h3 align='center'>How it works ?</h3>
<br>
Just go to www.lokly.in and enter the address. The request will be passed as an API to the backend where the predictions are made. The results are then returned back to the front-end. There is a option to careate an account to have access to more number of searches.
<hr>
<h3 align='center'>How we made it ?</h3>
<br>
A dataset with just Indian Addresses was provided. It was decided to go ahead with Stanford-ner-tagger to create our custom Part of Speech tagging. We started with pre-processing the data, removed the punctuations, converted all words to lowercase. We then tagged the words with the corresponding labels and trained the model using Stanford-ner-tagger. The server is created inside a docker container and it is deployed on AWS EC2 cloud storage. We trained 102082 words in total which sums up to around 13000 words with an average of 8 words per address. We acheived the accuracy of 83% with this model.
<hr>
<h3 align='center'>Scope for improvements ?</h3>
<br>
There is definitely a huge scope for future improvements with accurate data-tagging. Several new NLP algorithms have came and the accuracy if the model can be improved by trying out other Machine Learning Algorithms.
<hr>
<h3 align='center'>Team</h3>
<br>
This project was designed during my Summer Internship at 99 roomz in 2019 along with Arpit Jadiya, Manish Sharma and Spandan Singh
</div>

<div class="col-md-6"; >
<img src="static/lokly_home.png"; style="width:100%"; alt="Github">
<hr><br>
<img src="static/lokly_signup.png"; style="width:100%"; alt="Github">
<hr><br>
<img src="static/lokly_result.png"; style="width:100%"; alt="Github">
</div>
</div>
<br>
<br>
</body>
</html>